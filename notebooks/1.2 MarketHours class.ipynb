{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MarketHours class\n",
    "\n",
    "One of the biggest pains when dealing with trading data is handling the timestamps. This imposes many challenges due to:\n",
    "- Missing dates.\n",
    "- Holidays \n",
    "- Daytime Light Savings change.\n",
    "- Intraday plottings are inneficient if you plot.\n",
    "- Missalignment between trading natural days and the start of trading sessions.\n",
    "\n",
    "\n",
    "The MarketHours class help us handle all of this operations.\n",
    "\n",
    "Every symbol has a regular market hours like for example:\n",
    "- 8:00 - 17:00 for Europen stocks Monday-Friday\n",
    "- 8:00 - 19:00 for Forex Monday-Saturday\n",
    "\n",
    "This is the normal market hours but there can be several factors to change:\n",
    "- DST: It changes abruptly the hours\n",
    "- Holidays: Not open at all\n",
    "- Special days: Just open a few hours.\n",
    "\n",
    "Most of the functionalities of this class operate with intraday data. For daily candlesticks it can be used to know if a day should be trading or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "%matplotlib qt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "from traphing.data_classes import Velas\n",
    "from traphing.utils import Timeframes, unwrap, MarketHours\n",
    "from traphing.graph.Gl import gl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance of the class\n",
    "\n",
    "\n",
    "When instanciating the clase we can optionally include "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_market_hours = MarketHours()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MarketHours>\tobject has children:\n",
      "   <NoneType>\topen_time:\tNone\n",
      "   <NoneType>\tclose_time:\tNone\n",
      "   <list>\ttrading_days_list\n",
      "   <NoneType>\tspecial_days_dict:\tNone\n",
      "\n",
      "   <list>\ttrading_days_list has children:\n",
      "      <int>\ttrading_days_list[0]:\t0\n",
      "      <int>\ttrading_days_list[1]:\t1\n",
      "      <int>\ttrading_days_list[2]:\t2\n",
      "      <int>\ttrading_days_list[3]:\t3\n",
      "      <int>\ttrading_days_list[4]:\t4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unwrap(my_market_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction with Velas object\n",
    "\n",
    "The MarketHours class is intended to interact with the data from Velas objects. The Velas object has a set of functionalities that make use of the methods in MarketHours transparently. In the following, we will show some examples of this interaction.\n",
    "\n",
    "As always, we first need to import velas objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size ../tests/data/storage/M15/AUDCHF_M15.csv:  100400  rows\n"
     ]
    }
   ],
   "source": [
    "symbol_name = \"AUDCHF\"\n",
    "timeframe = Timeframes.M15\n",
    "storage_folder = \"../tests/data/storage/\"\n",
    "start_time = dt.datetime(2019,7,20)\n",
    "end_time = dt.datetime(2019,8,20)\n",
    "\n",
    "my_velas_M15 = Velas(symbol_name, timeframe)\n",
    "my_velas_M15.load_data_from_csv(storage_folder)\n",
    "my_velas_M15.set_time_interval(start_time, end_time, trim = False)\n",
    "\n",
    "timestamps_M15 = my_velas_M15.timestamps\n",
    "dates_M15 = my_velas_M15.dates\n",
    "unique_dates = dates_M15.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Iso calendar. The nightmare of time zones\n",
    "\n",
    "- DST is more political than rational.\n",
    "- The timestamps could be naive or aware regarding the timezone. If they are naive (no infomation), then UTC is assumed, so when calling isocalendar() we get????\n",
    "- There is the  Coordinated Universal Time (UTC)\n",
    "It is important to have a reference due to all the TimeZones, in our case we normalize to the ISO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekday and week number of  2019-07-22 00:00:00 None\n",
      "Weekday =  0\n",
      "Week number =  30\n"
     ]
    }
   ],
   "source": [
    "print (\"Weekday and week number of \",timestamps_M15[0], timestamps_M15[0].tzname())\n",
    "print (\"Weekday = \", timestamps_M15[0].weekday())\n",
    "print (\"Week number = \", timestamps_M15[0].week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "2019-07-22 00:00:00\n",
      "UTC\n",
      "2019-07-22 00:00:00+00:00\n",
      "UTC\n",
      "(2019, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "print(timestamps_M15[0].tz)\n",
    "print(timestamps_M15[0])\n",
    "import pytz \n",
    "from tzlocal import get_localzone # $ pip install tzlocal\n",
    "\n",
    "# get local timezone    \n",
    "local_tz = get_localzone()\n",
    "local_tz = \"UTC\"\n",
    "print(local_tz)\n",
    "tz_aware_time = timestamps_M15[0].tz_localize(local_tz) #Convert naive Timestamp to local time zone, or remove timezone from tz-aware Timestamp.\n",
    "print(tz_aware_time)\n",
    "print(tz_aware_time.tz)\n",
    "print(tz_aware_time.isocalendar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISO weekday and week number of  2019-07-22 00:00:00\n",
      "Weekday =  1\n",
      "Week number =  30\n"
     ]
    }
   ],
   "source": [
    "print (\"ISO weekday and week number of \",timestamps_M15[0])\n",
    "print (\"Weekday = \", timestamps_M15[0].isocalendar()[2])\n",
    "print (\"Week number = \", timestamps_M15[0].isocalendar()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by weekday number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 480, 1: 480, 2: 384, 3: 384, 4: 384}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_market_hours.get_number_of_samples_by_weekday_dict(timestamps_M15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5, 1: 5, 2: 4, 3: 4, 4: 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_market_hours.get_number_of_samples_by_weekday_dict(unique_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by natural days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([datetime.date(2019, 7, 22), datetime.date(2019, 7, 23), datetime.date(2019, 7, 24), datetime.date(2019, 7, 25), datetime.date(2019, 7, 26), datetime.date(2019, 7, 29), datetime.date(2019, 7, 30), datetime.date(2019, 7, 31), datetime.date(2019, 8, 1), datetime.date(2019, 8, 2), datetime.date(2019, 8, 5), datetime.date(2019, 8, 6), datetime.date(2019, 8, 7), datetime.date(2019, 8, 8), datetime.date(2019, 8, 9), datetime.date(2019, 8, 12), datetime.date(2019, 8, 13), datetime.date(2019, 8, 14), datetime.date(2019, 8, 15), datetime.date(2019, 8, 16), datetime.date(2019, 8, 19), datetime.date(2019, 8, 20)])\n",
      "DatetimeIndex(['2019-07-22 00:00:00', '2019-07-22 00:15:00',\n",
      "               '2019-07-22 00:30:00', '2019-07-22 00:45:00',\n",
      "               '2019-07-22 01:00:00', '2019-07-22 01:15:00',\n",
      "               '2019-07-22 01:30:00', '2019-07-22 01:45:00',\n",
      "               '2019-07-22 02:00:00', '2019-07-22 02:15:00',\n",
      "               '2019-07-22 02:30:00', '2019-07-22 02:45:00',\n",
      "               '2019-07-22 03:00:00', '2019-07-22 03:15:00',\n",
      "               '2019-07-22 03:30:00', '2019-07-22 03:45:00',\n",
      "               '2019-07-22 04:00:00', '2019-07-22 04:15:00',\n",
      "               '2019-07-22 04:30:00', '2019-07-22 04:45:00',\n",
      "               '2019-07-22 05:00:00', '2019-07-22 05:15:00',\n",
      "               '2019-07-22 05:30:00', '2019-07-22 05:45:00',\n",
      "               '2019-07-22 06:00:00', '2019-07-22 06:15:00',\n",
      "               '2019-07-22 06:30:00', '2019-07-22 06:45:00',\n",
      "               '2019-07-22 07:00:00', '2019-07-22 07:15:00',\n",
      "               '2019-07-22 07:30:00', '2019-07-22 07:45:00',\n",
      "               '2019-07-22 08:00:00', '2019-07-22 08:15:00',\n",
      "               '2019-07-22 08:30:00', '2019-07-22 08:45:00',\n",
      "               '2019-07-22 09:00:00', '2019-07-22 09:15:00',\n",
      "               '2019-07-22 09:30:00', '2019-07-22 09:45:00',\n",
      "               '2019-07-22 10:00:00', '2019-07-22 10:15:00',\n",
      "               '2019-07-22 10:30:00', '2019-07-22 10:45:00',\n",
      "               '2019-07-22 11:00:00', '2019-07-22 11:15:00',\n",
      "               '2019-07-22 11:30:00', '2019-07-22 11:45:00',\n",
      "               '2019-07-22 12:00:00', '2019-07-22 12:15:00',\n",
      "               '2019-07-22 12:30:00', '2019-07-22 12:45:00',\n",
      "               '2019-07-22 13:00:00', '2019-07-22 13:15:00',\n",
      "               '2019-07-22 13:30:00', '2019-07-22 13:45:00',\n",
      "               '2019-07-22 14:00:00', '2019-07-22 14:15:00',\n",
      "               '2019-07-22 14:30:00', '2019-07-22 14:45:00',\n",
      "               '2019-07-22 15:00:00', '2019-07-22 15:15:00',\n",
      "               '2019-07-22 15:30:00', '2019-07-22 15:45:00',\n",
      "               '2019-07-22 16:00:00', '2019-07-22 16:15:00',\n",
      "               '2019-07-22 16:30:00', '2019-07-22 16:45:00',\n",
      "               '2019-07-22 17:00:00', '2019-07-22 17:15:00',\n",
      "               '2019-07-22 17:30:00', '2019-07-22 17:45:00',\n",
      "               '2019-07-22 18:00:00', '2019-07-22 18:15:00',\n",
      "               '2019-07-22 18:30:00', '2019-07-22 18:45:00',\n",
      "               '2019-07-22 19:00:00', '2019-07-22 19:15:00',\n",
      "               '2019-07-22 19:30:00', '2019-07-22 19:45:00',\n",
      "               '2019-07-22 20:00:00', '2019-07-22 20:15:00',\n",
      "               '2019-07-22 20:30:00', '2019-07-22 20:45:00',\n",
      "               '2019-07-22 21:00:00', '2019-07-22 21:15:00',\n",
      "               '2019-07-22 21:30:00', '2019-07-22 21:45:00',\n",
      "               '2019-07-22 22:00:00', '2019-07-22 22:15:00',\n",
      "               '2019-07-22 22:30:00', '2019-07-22 22:45:00',\n",
      "               '2019-07-22 23:00:00', '2019-07-22 23:15:00',\n",
      "               '2019-07-22 23:30:00', '2019-07-22 23:45:00'],\n",
      "              dtype='datetime64[ns]', name='Timestamp', freq=None)\n",
      "DatetimeIndex(['2019-07-23 00:00:00', '2019-07-23 00:15:00',\n",
      "               '2019-07-23 00:30:00', '2019-07-23 00:45:00',\n",
      "               '2019-07-23 01:00:00', '2019-07-23 01:15:00',\n",
      "               '2019-07-23 01:30:00', '2019-07-23 01:45:00',\n",
      "               '2019-07-23 02:00:00', '2019-07-23 02:15:00',\n",
      "               '2019-07-23 02:30:00', '2019-07-23 02:45:00',\n",
      "               '2019-07-23 03:00:00', '2019-07-23 03:15:00',\n",
      "               '2019-07-23 03:30:00', '2019-07-23 03:45:00',\n",
      "               '2019-07-23 04:00:00', '2019-07-23 04:15:00',\n",
      "               '2019-07-23 04:30:00', '2019-07-23 04:45:00',\n",
      "               '2019-07-23 05:00:00', '2019-07-23 05:15:00',\n",
      "               '2019-07-23 05:30:00', '2019-07-23 05:45:00',\n",
      "               '2019-07-23 06:00:00', '2019-07-23 06:15:00',\n",
      "               '2019-07-23 06:30:00', '2019-07-23 06:45:00',\n",
      "               '2019-07-23 07:00:00', '2019-07-23 07:15:00',\n",
      "               '2019-07-23 07:30:00', '2019-07-23 07:45:00',\n",
      "               '2019-07-23 08:00:00', '2019-07-23 08:15:00',\n",
      "               '2019-07-23 08:30:00', '2019-07-23 08:45:00',\n",
      "               '2019-07-23 09:00:00', '2019-07-23 09:15:00',\n",
      "               '2019-07-23 09:30:00', '2019-07-23 09:45:00',\n",
      "               '2019-07-23 10:00:00', '2019-07-23 10:15:00',\n",
      "               '2019-07-23 10:30:00', '2019-07-23 10:45:00',\n",
      "               '2019-07-23 11:00:00', '2019-07-23 11:15:00',\n",
      "               '2019-07-23 11:30:00', '2019-07-23 11:45:00',\n",
      "               '2019-07-23 12:00:00', '2019-07-23 12:15:00',\n",
      "               '2019-07-23 12:30:00', '2019-07-23 12:45:00',\n",
      "               '2019-07-23 13:00:00', '2019-07-23 13:15:00',\n",
      "               '2019-07-23 13:30:00', '2019-07-23 13:45:00',\n",
      "               '2019-07-23 14:00:00', '2019-07-23 14:15:00',\n",
      "               '2019-07-23 14:30:00', '2019-07-23 14:45:00',\n",
      "               '2019-07-23 15:00:00', '2019-07-23 15:15:00',\n",
      "               '2019-07-23 15:30:00', '2019-07-23 15:45:00',\n",
      "               '2019-07-23 16:00:00', '2019-07-23 16:15:00',\n",
      "               '2019-07-23 16:30:00', '2019-07-23 16:45:00',\n",
      "               '2019-07-23 17:00:00', '2019-07-23 17:15:00',\n",
      "               '2019-07-23 17:30:00', '2019-07-23 17:45:00',\n",
      "               '2019-07-23 18:00:00', '2019-07-23 18:15:00',\n",
      "               '2019-07-23 18:30:00', '2019-07-23 18:45:00',\n",
      "               '2019-07-23 19:00:00', '2019-07-23 19:15:00',\n",
      "               '2019-07-23 19:30:00', '2019-07-23 19:45:00',\n",
      "               '2019-07-23 20:00:00', '2019-07-23 20:15:00',\n",
      "               '2019-07-23 20:30:00', '2019-07-23 20:45:00',\n",
      "               '2019-07-23 21:00:00', '2019-07-23 21:15:00',\n",
      "               '2019-07-23 21:30:00', '2019-07-23 21:45:00',\n",
      "               '2019-07-23 22:00:00', '2019-07-23 22:15:00',\n",
      "               '2019-07-23 22:30:00', '2019-07-23 22:45:00',\n",
      "               '2019-07-23 23:00:00', '2019-07-23 23:15:00',\n",
      "               '2019-07-23 23:30:00', '2019-07-23 23:45:00'],\n",
      "              dtype='datetime64[ns]', name='Timestamp', freq=None)\n",
      "DatetimeIndex(['2019-07-24 00:00:00', '2019-07-24 00:15:00',\n",
      "               '2019-07-24 00:30:00', '2019-07-24 00:45:00',\n",
      "               '2019-07-24 01:00:00', '2019-07-24 01:15:00',\n",
      "               '2019-07-24 01:30:00', '2019-07-24 01:45:00',\n",
      "               '2019-07-24 02:00:00', '2019-07-24 02:15:00',\n",
      "               '2019-07-24 02:30:00', '2019-07-24 02:45:00',\n",
      "               '2019-07-24 03:00:00', '2019-07-24 03:15:00',\n",
      "               '2019-07-24 03:30:00', '2019-07-24 03:45:00',\n",
      "               '2019-07-24 04:00:00', '2019-07-24 04:15:00',\n",
      "               '2019-07-24 04:30:00', '2019-07-24 04:45:00',\n",
      "               '2019-07-24 05:00:00', '2019-07-24 05:15:00',\n",
      "               '2019-07-24 05:30:00', '2019-07-24 05:45:00',\n",
      "               '2019-07-24 06:00:00', '2019-07-24 06:15:00',\n",
      "               '2019-07-24 06:30:00', '2019-07-24 06:45:00',\n",
      "               '2019-07-24 07:00:00', '2019-07-24 07:15:00',\n",
      "               '2019-07-24 07:30:00', '2019-07-24 07:45:00',\n",
      "               '2019-07-24 08:00:00', '2019-07-24 08:15:00',\n",
      "               '2019-07-24 08:30:00', '2019-07-24 08:45:00',\n",
      "               '2019-07-24 09:00:00', '2019-07-24 09:15:00',\n",
      "               '2019-07-24 09:30:00', '2019-07-24 09:45:00',\n",
      "               '2019-07-24 10:00:00', '2019-07-24 10:15:00',\n",
      "               '2019-07-24 10:30:00', '2019-07-24 10:45:00',\n",
      "               '2019-07-24 11:00:00', '2019-07-24 11:15:00',\n",
      "               '2019-07-24 11:30:00', '2019-07-24 11:45:00',\n",
      "               '2019-07-24 12:00:00', '2019-07-24 12:15:00',\n",
      "               '2019-07-24 12:30:00', '2019-07-24 12:45:00',\n",
      "               '2019-07-24 13:00:00', '2019-07-24 13:15:00',\n",
      "               '2019-07-24 13:30:00', '2019-07-24 13:45:00',\n",
      "               '2019-07-24 14:00:00', '2019-07-24 14:15:00',\n",
      "               '2019-07-24 14:30:00', '2019-07-24 14:45:00',\n",
      "               '2019-07-24 15:00:00', '2019-07-24 15:15:00',\n",
      "               '2019-07-24 15:30:00', '2019-07-24 15:45:00',\n",
      "               '2019-07-24 16:00:00', '2019-07-24 16:15:00',\n",
      "               '2019-07-24 16:30:00', '2019-07-24 16:45:00',\n",
      "               '2019-07-24 17:00:00', '2019-07-24 17:15:00',\n",
      "               '2019-07-24 17:30:00', '2019-07-24 17:45:00',\n",
      "               '2019-07-24 18:00:00', '2019-07-24 18:15:00',\n",
      "               '2019-07-24 18:30:00', '2019-07-24 18:45:00',\n",
      "               '2019-07-24 19:00:00', '2019-07-24 19:15:00',\n",
      "               '2019-07-24 19:30:00', '2019-07-24 19:45:00',\n",
      "               '2019-07-24 20:00:00', '2019-07-24 20:15:00',\n",
      "               '2019-07-24 20:30:00', '2019-07-24 20:45:00',\n",
      "               '2019-07-24 21:00:00', '2019-07-24 21:15:00',\n",
      "               '2019-07-24 21:30:00', '2019-07-24 21:45:00',\n",
      "               '2019-07-24 22:00:00', '2019-07-24 22:15:00',\n",
      "               '2019-07-24 22:30:00', '2019-07-24 22:45:00',\n",
      "               '2019-07-24 23:00:00', '2019-07-24 23:15:00',\n",
      "               '2019-07-24 23:30:00', '2019-07-24 23:45:00'],\n",
      "              dtype='datetime64[ns]', name='Timestamp', freq=None)\n",
      "DatetimeIndex(['2019-07-25 00:00:00', '2019-07-25 00:15:00',\n",
      "               '2019-07-25 00:30:00', '2019-07-25 00:45:00',\n",
      "               '2019-07-25 01:00:00', '2019-07-25 01:15:00',\n",
      "               '2019-07-25 01:30:00', '2019-07-25 01:45:00',\n",
      "               '2019-07-25 02:00:00', '2019-07-25 02:15:00',\n",
      "               '2019-07-25 02:30:00', '2019-07-25 02:45:00',\n",
      "               '2019-07-25 03:00:00', '2019-07-25 03:15:00',\n",
      "               '2019-07-25 03:30:00', '2019-07-25 03:45:00',\n",
      "               '2019-07-25 04:00:00', '2019-07-25 04:15:00',\n",
      "               '2019-07-25 04:30:00', '2019-07-25 04:45:00',\n",
      "               '2019-07-25 05:00:00', '2019-07-25 05:15:00',\n",
      "               '2019-07-25 05:30:00', '2019-07-25 05:45:00',\n",
      "               '2019-07-25 06:00:00', '2019-07-25 06:15:00',\n",
      "               '2019-07-25 06:30:00', '2019-07-25 06:45:00',\n",
      "               '2019-07-25 07:00:00', '2019-07-25 07:15:00',\n",
      "               '2019-07-25 07:30:00', '2019-07-25 07:45:00',\n",
      "               '2019-07-25 08:00:00', '2019-07-25 08:15:00',\n",
      "               '2019-07-25 08:30:00', '2019-07-25 08:45:00',\n",
      "               '2019-07-25 09:00:00', '2019-07-25 09:15:00',\n",
      "               '2019-07-25 09:30:00', '2019-07-25 09:45:00',\n",
      "               '2019-07-25 10:00:00', '2019-07-25 10:15:00',\n",
      "               '2019-07-25 10:30:00', '2019-07-25 10:45:00',\n",
      "               '2019-07-25 11:00:00', '2019-07-25 11:15:00',\n",
      "               '2019-07-25 11:30:00', '2019-07-25 11:45:00',\n",
      "               '2019-07-25 12:00:00', '2019-07-25 12:15:00',\n",
      "               '2019-07-25 12:30:00', '2019-07-25 12:45:00',\n",
      "               '2019-07-25 13:00:00', '2019-07-25 13:15:00',\n",
      "               '2019-07-25 13:30:00', '2019-07-25 13:45:00',\n",
      "               '2019-07-25 14:00:00', '2019-07-25 14:15:00',\n",
      "               '2019-07-25 14:30:00', '2019-07-25 14:45:00',\n",
      "               '2019-07-25 15:00:00', '2019-07-25 15:15:00',\n",
      "               '2019-07-25 15:30:00', '2019-07-25 15:45:00',\n",
      "               '2019-07-25 16:00:00', '2019-07-25 16:15:00',\n",
      "               '2019-07-25 16:30:00', '2019-07-25 16:45:00',\n",
      "               '2019-07-25 17:00:00', '2019-07-25 17:15:00',\n",
      "               '2019-07-25 17:30:00', '2019-07-25 17:45:00',\n",
      "               '2019-07-25 18:00:00', '2019-07-25 18:15:00',\n",
      "               '2019-07-25 18:30:00', '2019-07-25 18:45:00',\n",
      "               '2019-07-25 19:00:00', '2019-07-25 19:15:00',\n",
      "               '2019-07-25 19:30:00', '2019-07-25 19:45:00',\n",
      "               '2019-07-25 20:00:00', '2019-07-25 20:15:00',\n",
      "               '2019-07-25 20:30:00', '2019-07-25 20:45:00',\n",
      "               '2019-07-25 21:00:00', '2019-07-25 21:15:00',\n",
      "               '2019-07-25 21:30:00', '2019-07-25 21:45:00',\n",
      "               '2019-07-25 22:00:00', '2019-07-25 22:15:00',\n",
      "               '2019-07-25 22:30:00', '2019-07-25 22:45:00',\n",
      "               '2019-07-25 23:00:00', '2019-07-25 23:15:00',\n",
      "               '2019-07-25 23:30:00', '2019-07-25 23:45:00'],\n",
      "              dtype='datetime64[ns]', name='Timestamp', freq=None)\n"
     ]
    }
   ],
   "source": [
    "daily_groups = MarketHours.get_index_by_days_dict(timestamps_M15)\n",
    "\n",
    "print(daily_groups.keys())\n",
    "for i in range(4):\n",
    "    print (daily_groups[unique_dates[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation time\n",
    "\n",
    "Sometimes we will not be sure of the trading hours, or some shit. The things we can estimate are:\n",
    "- timeframe: \n",
    "- open_time and close_time:\n",
    "- usual_trading_days:\n",
    "- irregular_days:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Timeframes.M15: 15>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_market_hours.estimate_timeframe(timestamps_M15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open_time and close_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usual natural day market hours:  00:00:00  -  00:00:00\n"
     ]
    }
   ],
   "source": [
    "open_time, close_time = my_market_hours.estimate_open_close_time(timestamps_M15)\n",
    "print (\"Usual natural day market hours: \", str(open_time), \" - \", str(close_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### usual_trading_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of usual sample:  96\n"
     ]
    }
   ],
   "source": [
    "n_samples = my_market_hours.get_number_of_samples_per_trading_session(open_time,close_time, timeframe)\n",
    "print (\"Number of usual sample: \", n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "normal_trading_days_list = my_market_hours.estimate_normal_trading_days(timestamps_M15, open_time,close_time, timeframe)\n",
    "print(normal_trading_days_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_trading_days_dict = my_market_hours.estimate_special_trading_days_from_timestamps(timestamps_M15, open_time,close_time, timeframe, normal_trading_days_list)\n",
    "for key in special_trading_days_dict.keys():\n",
    "    print (special_trading_days_dict[key].close_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unwrapping the object again\n",
    "\n",
    "After the estimations, the internal data of the object is also modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MarketHours>\tobject has children:\n",
      "   <time>\topen_time\n",
      "   <time>\tclose_time\n",
      "   <list>\ttrading_days_list\n",
      "   <dict>\tspecial_days_dict\n",
      "   <Timeframes>\ttimeframe:\tTimeframes.M15\n",
      "\n",
      "   <dict>\tspecial_days_dict has children:\n",
      "      <SpecialMarketHours>\t2019-08-20\n",
      "\n",
      "      <SpecialMarketHours>\t2019-08-20 has children:\n",
      "         <time>\topen_time\n",
      "         <time>\tclose_time\n",
      "         <int>\tn_samples:\t86\n",
      "\n",
      "         <time>\tclose_time has children:\n",
      "\n",
      "         <time>\topen_time has children:\n",
      "\n",
      "   <list>\ttrading_days_list has children:\n",
      "      <int>\ttrading_days_list[0]:\t0\n",
      "      <int>\ttrading_days_list[1]:\t1\n",
      "      <int>\ttrading_days_list[2]:\t2\n",
      "      <int>\ttrading_days_list[3]:\t3\n",
      "      <int>\ttrading_days_list[4]:\t4\n",
      "\n",
      "   <time>\tclose_time has children:\n",
      "\n",
      "   <time>\topen_time has children:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unwrap(my_market_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete some samples to check functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_M15 = timestamps_M15[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date 2019-08-20 is different:\n",
      "\t Usual open time: \t 00:00:00 \t Special:  00:00:00\n",
      "\t Usual close time: \t 00:00:00 \t Special:  21:30:00\n",
      "\t Usual n samples: \t 96 \t\t Special:  86\n"
     ]
    }
   ],
   "source": [
    "special_trading_days_dict = my_market_hours.estimate_special_trading_days_from_timestamps(timestamps_M15, open_time,close_time, timeframe, normal_trading_days_list)\n",
    "for key in special_trading_days_dict.keys():\n",
    "    print(\"Date \" + str(key) + \" is different:\")\n",
    "    print(\"\\t Usual open time: \\t\", open_time, \"\\t Special: \", str(special_trading_days_dict[key].open_time))\n",
    "    print(\"\\t Usual close time: \\t\", close_time, \"\\t Special: \", str(special_trading_days_dict[key].close_time))\n",
    "    print(\"\\t Usual n samples: \\t\", n_samples, \"\\t\\t Special: \", str(special_trading_days_dict[key].n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of the object\n",
    "Once the properties of the days have been set or estimated we can use the object to easily obtain the information of everyday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if a day is special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special date:  2019-08-20\n"
     ]
    }
   ],
   "source": [
    "for date in unique_dates:\n",
    "    if (my_market_hours.is_special(date)):\n",
    "        print (\"Special date: \", date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if a day is a trading day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date 2019-07-23 is trading day? ->  True\n",
      "Date 2019-07-24 is trading day? ->  True\n",
      "Date 2019-07-25 is trading day? ->  True\n",
      "Date 2019-07-26 is trading day? ->  True\n",
      "Date 2019-07-27 is trading day? ->  False\n",
      "Date 2019-07-28 is trading day? ->  False\n",
      "Date 2019-07-29 is trading day? ->  True\n",
      "Date 2019-07-30 is trading day? ->  True\n",
      "Date 2019-07-31 is trading day? ->  True\n",
      "Date 2019-08-01 is trading day? ->  True\n",
      "Date 2019-08-02 is trading day? ->  True\n",
      "Date 2019-08-03 is trading day? ->  False\n",
      "Date 2019-08-04 is trading day? ->  False\n",
      "Date 2019-08-05 is trading day? ->  True\n",
      "Date 2019-08-06 is trading day? ->  True\n",
      "Date 2019-08-07 is trading day? ->  True\n",
      "Date 2019-08-08 is trading day? ->  True\n",
      "Date 2019-08-09 is trading day? ->  True\n",
      "Date 2019-08-10 is trading day? ->  False\n",
      "Date 2019-08-11 is trading day? ->  False\n",
      "Date 2019-08-12 is trading day? ->  True\n",
      "Date 2019-08-13 is trading day? ->  True\n",
      "Date 2019-08-14 is trading day? ->  True\n",
      "Date 2019-08-15 is trading day? ->  True\n",
      "Date 2019-08-16 is trading day? ->  True\n",
      "Date 2019-08-17 is trading day? ->  False\n",
      "Date 2019-08-18 is trading day? ->  False\n",
      "Date 2019-08-19 is trading day? ->  True\n",
      "Date 2019-08-20 is trading day? ->  True\n"
     ]
    }
   ],
   "source": [
    "first_date = unique_dates[0]\n",
    "last_date = unique_dates[-1]\n",
    "\n",
    "date = first_date\n",
    "while (date < last_date):\n",
    "    date += dt.timedelta(days = 1)\n",
    "    is_trading_day = my_market_hours.is_trading_day(date)\n",
    "    \n",
    "    print (\"Date \" + str(date) + \" is trading day? -> \", is_trading_day)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
